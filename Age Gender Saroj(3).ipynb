{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a2a10ad-6d4b-428c-9bf2-ef202f58d799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total valid images loaded: 23708\n",
      "✅ Data preprocessed and ready for model training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "image_dir = \"UTKFace/UTKFace\"  # This is the correct path\n",
    "\n",
    "data = []\n",
    "age_labels = []\n",
    "gender_labels = []\n",
    "\n",
    "for filename in os.listdir(image_dir):\n",
    "    try:\n",
    "        if not filename.endswith(\".jpg\"):\n",
    "            continue\n",
    "\n",
    "        age, gender, *_ = filename.split(\"_\")\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "\n",
    "        data.append(img)\n",
    "        age_labels.append(int(age))\n",
    "        gender_labels.append(int(gender))\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"✅ Total valid images loaded: {len(data)}\")\n",
    "\n",
    "X = np.array(data) / 255.0\n",
    "y_age = np.array(age_labels)\n",
    "y_gender = np.array(gender_labels)\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_age_train, y_age_test, y_gender_train, y_gender_test = train_test_split(\n",
    "    X, y_age, y_gender, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"✅ Data preprocessed and ready for model training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "789731c4-c97c-4524-b7ec-a8544bb0d6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ batch_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ batch_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_3               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,416</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gender_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ age_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │ batch_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │ batch_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_3               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m524,416\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gender_output (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │             \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ age_output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │             \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">915,010</span> (3.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m915,010\u001b[0m (3.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">914,050</span> (3.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m914,050\u001b[0m (3.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Input Layer\n",
    "input_layer = Input(shape=(64, 64, 3))\n",
    "\n",
    "# Shared Convolutional Base\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output 1: Gender Classification\n",
    "gender_output = Dense(1, activation='sigmoid', name='gender_output')(x)\n",
    "\n",
    "# Output 2: Age Regression\n",
    "age_output = Dense(1, activation='linear', name='age_output')(x)\n",
    "\n",
    "# Define Model\n",
    "model = Model(inputs=input_layer, outputs=[gender_output, age_output])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'gender_output': 'binary_crossentropy',\n",
    "        'age_output': 'mae'\n",
    "    },\n",
    "    metrics={\n",
    "        'gender_output': 'accuracy',\n",
    "        'age_output': 'mae'\n",
    "    }\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbaa6f22-9ea3-45aa-8703-a52a3fdfe3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 156ms/step - age_output_loss: 13.5902 - age_output_mae: 13.5902 - gender_output_accuracy: 0.6966 - gender_output_loss: 1.0561 - loss: 14.6464 - val_age_output_loss: 13.6273 - val_age_output_mae: 13.6271 - val_gender_output_accuracy: 0.7132 - val_gender_output_loss: 0.5378 - val_loss: 14.1650\n",
      "Epoch 2/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 152ms/step - age_output_loss: 9.3962 - age_output_mae: 9.3962 - gender_output_accuracy: 0.7986 - gender_output_loss: 0.5221 - loss: 9.9183 - val_age_output_loss: 12.2695 - val_age_output_mae: 12.2659 - val_gender_output_accuracy: 0.8392 - val_gender_output_loss: 0.3547 - val_loss: 12.6216\n",
      "Epoch 3/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 155ms/step - age_output_loss: 8.0955 - age_output_mae: 8.0955 - gender_output_accuracy: 0.8249 - gender_output_loss: 0.4029 - loss: 8.4984 - val_age_output_loss: 7.1356 - val_age_output_mae: 7.1265 - val_gender_output_accuracy: 0.8635 - val_gender_output_loss: 0.3254 - val_loss: 7.4524\n",
      "Epoch 4/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 154ms/step - age_output_loss: 7.9876 - age_output_mae: 7.9876 - gender_output_accuracy: 0.8397 - gender_output_loss: 0.3587 - loss: 8.3462 - val_age_output_loss: 11.1051 - val_age_output_mae: 11.1082 - val_gender_output_accuracy: 0.8561 - val_gender_output_loss: 0.3156 - val_loss: 11.4249\n",
      "Epoch 5/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 152ms/step - age_output_loss: 7.4130 - age_output_mae: 7.4130 - gender_output_accuracy: 0.8490 - gender_output_loss: 0.3329 - loss: 7.7459 - val_age_output_loss: 7.1433 - val_age_output_mae: 7.1316 - val_gender_output_accuracy: 0.8635 - val_gender_output_loss: 0.2949 - val_loss: 7.4275\n",
      "Epoch 6/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 151ms/step - age_output_loss: 7.2620 - age_output_mae: 7.2619 - gender_output_accuracy: 0.8626 - gender_output_loss: 0.3108 - loss: 7.5727 - val_age_output_loss: 7.1022 - val_age_output_mae: 7.1018 - val_gender_output_accuracy: 0.8719 - val_gender_output_loss: 0.2847 - val_loss: 7.3877\n",
      "Epoch 7/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 152ms/step - age_output_loss: 6.8766 - age_output_mae: 6.8765 - gender_output_accuracy: 0.8596 - gender_output_loss: 0.3147 - loss: 7.1912 - val_age_output_loss: 8.1184 - val_age_output_mae: 8.1133 - val_gender_output_accuracy: 0.8714 - val_gender_output_loss: 0.2813 - val_loss: 8.3959\n",
      "Epoch 8/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 155ms/step - age_output_loss: 6.4619 - age_output_mae: 6.4619 - gender_output_accuracy: 0.8666 - gender_output_loss: 0.2984 - loss: 6.7603 - val_age_output_loss: 6.4547 - val_age_output_mae: 6.4546 - val_gender_output_accuracy: 0.8798 - val_gender_output_loss: 0.2825 - val_loss: 6.7382\n",
      "Epoch 9/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 152ms/step - age_output_loss: 6.3584 - age_output_mae: 6.3584 - gender_output_accuracy: 0.8700 - gender_output_loss: 0.2972 - loss: 6.6556 - val_age_output_loss: 7.2538 - val_age_output_mae: 7.2441 - val_gender_output_accuracy: 0.8867 - val_gender_output_loss: 0.2691 - val_loss: 7.5148\n",
      "Epoch 10/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 151ms/step - age_output_loss: 6.1299 - age_output_mae: 6.1299 - gender_output_accuracy: 0.8665 - gender_output_loss: 0.2939 - loss: 6.4238 - val_age_output_loss: 7.4247 - val_age_output_mae: 7.4278 - val_gender_output_accuracy: 0.8830 - val_gender_output_loss: 0.2686 - val_loss: 7.6978\n",
      "Epoch 11/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 149ms/step - age_output_loss: 5.8954 - age_output_mae: 5.8954 - gender_output_accuracy: 0.8752 - gender_output_loss: 0.2807 - loss: 6.1761 - val_age_output_loss: 6.4092 - val_age_output_mae: 6.4157 - val_gender_output_accuracy: 0.8840 - val_gender_output_loss: 0.2983 - val_loss: 6.7156\n",
      "Epoch 12/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 150ms/step - age_output_loss: 5.7940 - age_output_mae: 5.7939 - gender_output_accuracy: 0.8845 - gender_output_loss: 0.2618 - loss: 6.0558 - val_age_output_loss: 7.3275 - val_age_output_mae: 7.3226 - val_gender_output_accuracy: 0.8835 - val_gender_output_loss: 0.2606 - val_loss: 7.5847\n",
      "Epoch 13/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 150ms/step - age_output_loss: 5.6588 - age_output_mae: 5.6588 - gender_output_accuracy: 0.8898 - gender_output_loss: 0.2546 - loss: 5.9134 - val_age_output_loss: 6.3413 - val_age_output_mae: 6.3362 - val_gender_output_accuracy: 0.8835 - val_gender_output_loss: 0.2651 - val_loss: 6.6027\n",
      "Epoch 14/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 149ms/step - age_output_loss: 5.5705 - age_output_mae: 5.5705 - gender_output_accuracy: 0.8901 - gender_output_loss: 0.2510 - loss: 5.8214 - val_age_output_loss: 6.5803 - val_age_output_mae: 6.5752 - val_gender_output_accuracy: 0.8909 - val_gender_output_loss: 0.2456 - val_loss: 6.8225\n",
      "Epoch 15/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 150ms/step - age_output_loss: 5.4430 - age_output_mae: 5.4430 - gender_output_accuracy: 0.8927 - gender_output_loss: 0.2468 - loss: 5.6898 - val_age_output_loss: 6.3899 - val_age_output_mae: 6.3900 - val_gender_output_accuracy: 0.8730 - val_gender_output_loss: 0.3221 - val_loss: 6.7145\n",
      "Epoch 16/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 150ms/step - age_output_loss: 5.4453 - age_output_mae: 5.4453 - gender_output_accuracy: 0.8911 - gender_output_loss: 0.2461 - loss: 5.6914 - val_age_output_loss: 7.1911 - val_age_output_mae: 7.1925 - val_gender_output_accuracy: 0.8687 - val_gender_output_loss: 0.3061 - val_loss: 7.5005\n",
      "Epoch 17/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 150ms/step - age_output_loss: 5.2319 - age_output_mae: 5.2319 - gender_output_accuracy: 0.8954 - gender_output_loss: 0.2365 - loss: 5.4684 - val_age_output_loss: 6.2876 - val_age_output_mae: 6.2882 - val_gender_output_accuracy: 0.8835 - val_gender_output_loss: 0.2881 - val_loss: 6.5782\n",
      "Epoch 18/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 151ms/step - age_output_loss: 5.2369 - age_output_mae: 5.2369 - gender_output_accuracy: 0.8954 - gender_output_loss: 0.2319 - loss: 5.4688 - val_age_output_loss: 6.3857 - val_age_output_mae: 6.3874 - val_gender_output_accuracy: 0.8935 - val_gender_output_loss: 0.2614 - val_loss: 6.6502\n",
      "Epoch 19/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 152ms/step - age_output_loss: 5.0622 - age_output_mae: 5.0622 - gender_output_accuracy: 0.9018 - gender_output_loss: 0.2204 - loss: 5.2826 - val_age_output_loss: 6.3539 - val_age_output_mae: 6.3585 - val_gender_output_accuracy: 0.8898 - val_gender_output_loss: 0.2927 - val_loss: 6.6534\n",
      "Epoch 20/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 151ms/step - age_output_loss: 4.9464 - age_output_mae: 4.9464 - gender_output_accuracy: 0.8985 - gender_output_loss: 0.2297 - loss: 5.1761 - val_age_output_loss: 6.2455 - val_age_output_mae: 6.2597 - val_gender_output_accuracy: 0.8930 - val_gender_output_loss: 0.2646 - val_loss: 6.5262\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     {'gender_output': y_gender_train, 'age_output': y_age_train},\n",
    "#     validation_split=0.1,\n",
    "#     epochs=20,\n",
    "#     batch_size=64\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5b726dd-9d37-4933-90d0-d06482aff6dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Gender accuracy\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender_output_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_gender_output_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Gender Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gender accuracy\n",
    "plt.plot(history.history['gender_output_accuracy'], label='Gender Accuracy')\n",
    "plt.plot(history.history['val_gender_output_accuracy'], label='Val Gender Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Gender Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# Age MAE\n",
    "plt.plot(history.history['age_output_mae'], label='Age MAE')\n",
    "plt.plot(history.history['val_age_output_mae'], label='Val Age MAE')\n",
    "plt.legend()\n",
    "plt.title(\"Age MAE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6eeca9-0a67-4612-a2af-92266f7526e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - age_output_loss: 6.2934 - age_output_mae: 6.2935 - gender_output_accuracy: 0.8908 - gender_output_loss: 0.2736 - loss: 6.5672\n",
      "\n",
      "Test Loss & Metrics:\n",
      "loss: 6.5641\n",
      "compile_metrics: 0.2559\n",
      "gender_output_loss: 6.2990\n",
      "age_output_loss: 6.3071\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, {'gender_output': y_gender_test, 'age_output': y_age_test})\n",
    "print(\"\\nTest Loss & Metrics:\")\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26292c6b-67bf-4191-a4b3-207631955704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Predict gender and age on test data\n",
    "gender_pred_prob, age_pred = model.predict(X_test)\n",
    "\n",
    "# Since gender is sigmoid output, convert to binary labels\n",
    "gender_pred = (gender_pred_prob > 0.5).astype(int).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf09efd3-7c45-486b-807b-f0ab316bdd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Classification Metrics:\n",
      "Confusion Matrix:\n",
      " [[2270  215]\n",
      " [ 293 1964]]\n",
      "Accuracy: 0.8929\n",
      "Precision: 0.9013\n",
      "Recall: 0.8702\n",
      "F1 Score: 0.8855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Gender Classification Metrics:\")\n",
    "\n",
    "cm = confusion_matrix(y_gender_test, gender_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "acc = accuracy_score(y_gender_test, gender_pred)\n",
    "prec = precision_score(y_gender_test, gender_pred)\n",
    "rec = recall_score(y_gender_test, gender_pred)\n",
    "f1 = f1_score(y_gender_test, gender_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73bfbd3f-b958-4af5-84d3-fb4cce90e1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Age Regression Metrics:\n",
      "R² Score: 0.8021\n",
      "MAE: 6.3071\n",
      "MSE: 78.5671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "print(\"\\nAge Regression Metrics:\")\n",
    "\n",
    "r2 = r2_score(y_age_test, age_pred)\n",
    "mae = mean_absolute_error(y_age_test, age_pred)\n",
    "mse = mean_squared_error(y_age_test, age_pred)\n",
    "\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d648859-f1b4-4dba-a2ca-3d68f0c05cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('age_gender_model3.keras', include_optimizer=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f57a80d-049d-49a6-9b4e-8ebbc53e3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "\n",
    "model = load_model('age_gender_model1.keras', compile=False)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'gender_output': 'binary_crossentropy',\n",
    "        'age_output': MeanAbsoluteError()\n",
    "    },\n",
    "    metrics={\n",
    "        'gender_output': 'accuracy',\n",
    "        'age_output': MeanAbsoluteError()\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0c74e3-87e5-4f1d-ba47-68697c23b53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "\n",
    "# Load the trained model and compile explicitly\n",
    "model = load_model('age_gender_model3.keras', compile=False)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'gender_output': 'binary_crossentropy',\n",
    "        'age_output': MeanAbsoluteError()\n",
    "    },\n",
    "    metrics={\n",
    "        'gender_output': 'accuracy',\n",
    "        'age_output': MeanAbsoluteError()\n",
    "    }\n",
    ")\n",
    "\n",
    "# Load Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def preprocess_face(face_img):\n",
    "    \"\"\"Resize, normalize, and reshape face image for prediction.\"\"\"\n",
    "    face_img = cv2.resize(face_img, (64, 64))\n",
    "    face_img = face_img.astype('float32') / 255.0\n",
    "    face_img = np.expand_dims(face_img, axis=0)  # Shape: (1, 64, 64, 3)\n",
    "    return face_img\n",
    "\n",
    "# Start webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract the face ROI from original frame\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Preprocess for model\n",
    "        input_img = preprocess_face(face_img)\n",
    "\n",
    "        # Predict gender and age\n",
    "        gender_pred_prob, age_pred = model.predict(input_img)\n",
    "        gender_label = \"Female\" if gender_pred_prob[0][0] > 0.5 else \"Male\"\n",
    "        age_label = int(age_pred[0][0])\n",
    "\n",
    "        # Draw bounding box on the face\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        # Text position above the box\n",
    "        text = f\"{gender_label}, Age: {age_label}\"\n",
    "        (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
    "        cv2.rectangle(frame, (x, y - text_height - 10), (x + text_width, y), (0, 255, 0), -1)  # Filled box for text\n",
    "        cv2.putText(frame, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Age & Gender Prediction', frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e0c8ec-dc86-429e-9636-f14df74193e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from collections import deque\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('age_gender_model3.keras', compile=False)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'gender_output': 'binary_crossentropy',\n",
    "        'age_output': MeanAbsoluteError()\n",
    "    },\n",
    "    metrics={\n",
    "        'gender_output': 'accuracy',\n",
    "        'age_output': MeanAbsoluteError()\n",
    "    }\n",
    ")\n",
    "\n",
    "# Load Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# For stabilizing predictions\n",
    "age_history = {}\n",
    "gender_history = {}\n",
    "MAX_HISTORY = 10\n",
    "\n",
    "def preprocess_face(face_img):\n",
    "    face_img = cv2.resize(face_img, (64, 64))\n",
    "    face_img = face_img.astype('float32') / 255.0\n",
    "    return np.expand_dims(face_img, axis=0)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    for idx, (x, y, w, h) in enumerate(faces):\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        input_img = preprocess_face(face_img)\n",
    "\n",
    "        gender_pred_prob, age_pred = model.predict(input_img, verbose=0)\n",
    "        gender_label = \"Female\" if gender_pred_prob[0][0] > 0.5 else \"Male\"\n",
    "        age_value = int(age_pred[0][0])\n",
    "\n",
    "        # Keep prediction history\n",
    "        if idx not in age_history:\n",
    "            age_history[idx] = deque(maxlen=MAX_HISTORY)\n",
    "            gender_history[idx] = deque(maxlen=MAX_HISTORY)\n",
    "\n",
    "        age_history[idx].append(age_value)\n",
    "        gender_history[idx].append(gender_label)\n",
    "\n",
    "        # Stable prediction\n",
    "        stable_age = int(np.median(age_history[idx]))\n",
    "        stable_gender = max(set(gender_history[idx]), key=gender_history[idx].count)\n",
    "\n",
    "        text = f\"{stable_gender}, Age: {stable_age}\"\n",
    "        (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
    "        cv2.rectangle(frame, (x, y - th - 10), (x + tw, y), (0, 255, 0), -1)\n",
    "        cv2.putText(frame, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Age & Gender Prediction (Stable)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4e838-2189-461c-9fb0-aba3d3df6522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
